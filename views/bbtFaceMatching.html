<!DOCTYPE html>
<html>
<head>
  <script src="js/face-api.js"></script>
  <script src="js/commons.js"></script>
  <script src="js/bbt.js"></script>
  <link rel="stylesheet" href="styles.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/css/materialize.css">
  <script type="text/javascript" src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/js/materialize.min.js"></script>
</head>
<body>
  <div id="navbar"></div>
  <div class="center-content page-container">
    <div>
      <div style="position: relative" class="margin">
        <video onloadedmetadata="onPlay(this)" id="inputVideo" autoplay muted playsinline></video>
        <canvas id="overlay" />
      </div>
      <button id="click-photo" onclick="capt()">Click Photo</button>
      <div class="row center-content" id="loader">
        <input disabled value="" id="status" type="text" class="bold">
        <div class="progress">
          <div class="indeterminate"></div>
        </div>
      </div>
      <div class="row center-content">
        <!-- <img id="face" src="" height="80" /> -->
      </div>
      <div class="row">
        <label for="prediction">Prediction:</label>
        <input disabled value="-" id="prediction" type="text" class="bold">
      </div>
      <div class="row">
        <label for="time">Time:</label>
        <input disabled value="-" id="time" type="text" class="bold">
      </div>
      <div class="row">
        <label for="fps">Estimated Fps:</label>
        <input disabled value="-" id="fps" type="text" class="bold">
      </div>
      
      <canvas id="canvas" width="320" height="240"></canvas>
      <img id="pic1" src="" height="80">
    </div>
  </div>

  <script>
    let interval = 2000

    let isStop = false
    let faceMatcher = null
    let currImageIdx = 2, currClassIdx = 0
    let to = null

    function setStatusText(text) {
      $('#status').val(text)
    }

    function displayTimeStats(timeInMs) {
      $('#time').val(`${timeInMs} ms`)
      $('#fps').val(`${faceapi.utils.round(1000 / timeInMs)}`)
    }

    function displayImage(src) {
      getImg().src = src
    }

    async function runFaceRecognition() {
      async function next() {
        // const input = await faceapi.fetchImage("amy/amy5.png")
        // const input = await faceapi.fetchImage("trainings/1/amy5.png")
        // // console.log(input)
        // // const input = await requestExternalImage("https://storage.googleapis.com/envisions_desk_dev/uploads/users/735/profile/2021-12/596a33eeb5b4ccb97ec7edf45233a661.png")
        // // const input = await requestExternalImage("https://storage.googleapis.com/envisions_desk_dev/uploads/users/735/profile/2021-12/ef3cb10b7a530a478bc89f2d88f182a2.jpg")
        // // const input = await requestExternalImage("https://storage.googleapis.com/envisions_desk_dev/uploads/users/85/profile/2021-12/64bc6a620e61378e51f5c4a7c1a80967.png")
        // // const input = await requestExternalImage("https://storage.googleapis.com/envisions_desk_dev/uploads/users/85/profile/2021-12/1c5e56bc9620ddb57d68096f046d462e.png")
        // // const input = await requestExternalImage("https://storage.googleapis.com/envisions_desk_dev/uploads/users/85/profile/2021-12/c102095bda8d55ed9cb4ca1bc8d52e1f.png")
        // const imgEl = $('#face').get(0)
        // imgEl.src = input.src

        // const ts = Date.now()
        // const descriptor = await faceapi.computeFaceDescriptor(input)
        // displayTimeStats(Date.now() - ts)

        // const bestMatch = faceMatcher.findBestMatch(descriptor)
        // $('#prediction').val(bestMatch.toString())
        // // console.log(descriptor,bestMatch)
        // console.log(bestMatch.toString())

        // currImageIdx = currClassIdx === (classes.length - 1)
        //   ? currImageIdx + 1
        //   : currImageIdx
        // currClassIdx = (currClassIdx + 1) % classes.length

        // currImageIdx = (currImageIdx % 6) || 2
        // to = setTimeout(next, interval)
      }
      await next(0, 0)
    }

    let forwardTimes = []
    let video = document.querySelector("#inputVideo");
    let canvas = document.querySelector("#canvas");

    async function capt() {
      canvas.getContext('2d').drawImage(video, 0, 0, canvas.width, canvas.height);
      let image_data_url = canvas.toDataURL('image/png');
      urltoFile(image_data_url, 'capture.png','image/png')
      .then(async function(file){
        // const imgFile = file.get(0).files[0]
        const input = await faceapi.bufferToImage(file)
        const ts = Date.now()
        const descriptor = await faceapi.computeFaceDescriptor(input)
        displayTimeStats(Date.now() - ts)

        const bestMatch = faceMatcher.findBestMatch(descriptor)
        $('#prediction').val(bestMatch.toString())
        currImageIdx = currClassIdx === (classes.length - 1)
          ? currImageIdx + 1
          : currImageIdx
        currClassIdx = (currClassIdx + 1) % classes.length

        currImageIdx = (currImageIdx % 6) || 2
      });
    }

    function urltoFile(url, filename, mimeType){
        return (fetch(url)
            .then(function(res){return res.arrayBuffer();})
            .then(function(buf){return new File([buf], filename,{type:mimeType});})
        );
    }

    async function run() {
      try {
        setStatusText('loading model file...')

        await faceapi.loadFaceRecognitionModel('/')

        setStatusText('computing initial descriptors...')

        faceMatcher = await createBbtFaceMatcher(1)
        $('#loader').hide()

        runFaceRecognition()

        // load face detection model
        // await changeFaceDetector(TINY_FACE_DETECTOR)
        // changeInputSize(128)

        // try to access users webcam and stream the images
        // to the video element
        const stream = await navigator.mediaDevices.getUserMedia({ video: {} })
        const videoEl = $('#inputVideo').get(0)
        videoEl.srcObject = stream
      } catch (err) {
        console.error(err)
      }
    }
    async function onPlay() {
      const videoEl = $('#inputVideo').get(0)

      if(videoEl.paused || videoEl.ended || !isFaceDetectionModelLoaded())
        return setTimeout(() => onPlay())

      const options = getFaceDetectorOptions()
      const ts = Date.now()
      const result = await faceapi.detectSingleFace(videoEl, options)

      updateTimeStats(Date.now() - ts)

      if (result) {
        const canvas = $('#overlay').get(0)
        const dims = faceapi.matchDimensions(canvas, videoEl, true)
        faceapi.draw.drawDetections(canvas, faceapi.resizeResults(result, dims))
      }
      setTimeout(() => onPlay())
    }
    $(document).ready(function() {
      run()
      console.log(window.location.href)
      // fetch('http://localhost/smartcampus-unpad/Fr/api.php', {mode: 'no-cors'})
      // .then(res => console.log(res))
    })
  </script>
</body>
</html>